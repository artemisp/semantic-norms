{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import openai\n",
    "import sys\n",
    "sys.path.insert(1, '../../model/')\n",
    "import eval\n",
    "openai.api_key = \"<OPENAI-KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"concept_properties\" # \"feature_norms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompts(prompt_type):\n",
    "\tnoun2sent = {}\n",
    "\twith open(f\"../data/datasets/{DATASET}/queries\" + prompt_type + \".prop\", \"r\") as f:\n",
    "\t\tfor raw_data in f.readlines():\n",
    "\t\t\tnoun = raw_data.split(\" :: \")[0]\n",
    "\t\t\tsent = raw_data.split(\" :: \")[1][:-1]\n",
    "\t\t\tnoun2sent[noun] = sent\n",
    "\treturn noun2sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun2prop = pickle.load(open(f\"../data/datasets/{DATASET}/noun2property/noun2prop.p\", \"rb\"))\n",
    "candidate_adjs = []\n",
    "for noun, props in noun2prop.items():\n",
    "    candidate_adjs += props\n",
    "candidate_adjs = list(set(candidate_adjs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt3_scores(sentence):\n",
    "    response = openai.Completion.create(\n",
    "                        engine=\"text-ada-001\",\n",
    "                        prompt=sentence,\n",
    "                        temperature=1.0,\n",
    "                        max_tokens=0,\n",
    "                        top_p=1,\n",
    "                        echo=True,\n",
    "                        logprobs=1,\n",
    "                        frequency_penalty=0,\n",
    "                        presence_penalty=0\n",
    "                    )\n",
    "    tokens = dict(dict(dict(dict(response)['choices'][0]))['logprobs'])['tokens']\n",
    "    logprobs = dict(dict(dict(dict(response)['choices'][0]))['logprobs'])['token_logprobs']\n",
    "    list_of_tokens = []\n",
    "    current_list = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token != \"\\n\":\n",
    "            current_list.append((token, logprobs[i]))\n",
    "        else:\n",
    "            list_of_tokens.append(current_list)\n",
    "            current_list = []\n",
    "    list_of_tokens.append(current_list)\n",
    "    scores = []\n",
    "    for token_list in list_of_tokens:\n",
    "        # for i, (token, prob) in enumerate(token_list):\n",
    "        #     if token == \" is\" or token == \" are\" or token == \" be\":\n",
    "        #         target_index = i + 1\n",
    "        #         break\n",
    "        current_scores = [s for t, s in token_list[target_index:]]\n",
    "        current_scores = [s for _, s in token_list if s != None]\n",
    "        scores.append(2 ** (-np.mean(current_scores)))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_types = [\"plural_most\", \"singular_can_be\", \"singular_usually\", \"singular_generally\", \"singular\", \"plural_all\", \"plural_can_be\", \"plural_generally\", \"plural_some\", \"plural_usually\", \"plural\"]\n",
    "for pt in prompt_types:\n",
    "    noun2sent = get_prompts(prompt_type = pt)\n",
    "    noun2predicts = {}\n",
    "    for noun, sent in tqdm(noun2sent.items()):\n",
    "        noun2predicts[noun] = []\n",
    "        sentences = [sent.replace('[MASK]', adj) for adj in candidate_adjs]\n",
    "        input2gpt3 = \"\\n\".join(sentences)\n",
    "        scores = get_gpt3_scores(input2gpt3)\n",
    "        predicts = [(candidate_adjs[ind], float(scores[ind])) for ind in np.argsort(scores)]\n",
    "        predicts.sort(key=lambda x: x[0])\n",
    "        predicts.sort(key=lambda x: x[1])\n",
    "        noun2predicts[noun] = [pred[0] for pred in predicts]\n",
    "    eval.evaluate(noun2predicts, noun2prop)\n",
    "    eval.evaluate_acc(noun2predicts, noun2prop)\n",
    "    eval.evaluate_concretness(noun2predicts)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d7325128c788ebe58d0531710a6fa19c8b08d83880d6b610174ef1183dc68e0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
